{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d28eab-e41c-4116-be3b-2513acae4d00",
   "metadata": {},
   "source": [
    "## Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69291d8-f7d1-49c8-9d4f-5c33aa0647fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde61c2-7ac3-427e-beed-f43b504fbc0f",
   "metadata": {},
   "source": [
    "## Функции предобработки изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ed0db5-67dd-4a5d-bbd4-379863f96ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_density(cluster_mask):\n",
    "    logger.debug(\"Calculating cluster density.\")\n",
    "    contours, _ = cv2.findContours(cluster_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(contour) for contour in contours]\n",
    "    total_area = sum(areas)\n",
    "    logger.debug(f\"Total area calculated: {total_area}\")\n",
    "    return total_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204729c2-6d08-4f9e-8ae5-70c89e331b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_vertical_contours(contours):\n",
    "    logger.debug(\"Combining vertical contours.\")\n",
    "    combined_contours = []\n",
    "    skip = set()\n",
    "\n",
    "    for i, cnt1 in enumerate(contours):\n",
    "        if i in skip:\n",
    "            continue\n",
    "\n",
    "        x1, y1, w1, h1 = cv2.boundingRect(cnt1)\n",
    "        combined_rect = [x1, y1, x1 + w1, y1 + h1]  # [left, top, right, bottom]\n",
    "\n",
    "        for j, cnt2 in enumerate(contours):\n",
    "            if i == j or j in skip:\n",
    "                continue\n",
    "\n",
    "            x2, y2, w2, h2 = cv2.boundingRect(cnt2)\n",
    "            if (x1 <= x2 <= x1 + w1) or (x2 <= x1 <= x2 + w2):  # Check vertical overlap\n",
    "                combined_rect[0] = min(combined_rect[0], x2)\n",
    "                combined_rect[1] = min(combined_rect[1], y2)\n",
    "                combined_rect[2] = max(combined_rect[2], x2 + w2)\n",
    "                combined_rect[3] = max(combined_rect[3], y2 + h2)\n",
    "                skip.add(j)\n",
    "\n",
    "        combined_contours.append(combined_rect)\n",
    "        logger.debug(f\"Combined rect: {combined_rect}\")\n",
    "\n",
    "    return combined_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a05a024-0e2a-48d2-8ce4-ebb4350c1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(path):\n",
    "    logger.info(f\"Preprocessing image: {path}\")\n",
    "    image = cv2.imread(path)\n",
    "    if image is None:\n",
    "        logger.error(f\"Failed to read image from path: {path}\")\n",
    "        return []\n",
    "\n",
    "    logger.debug(\"Applying sharpening filter.\")\n",
    "    sharp_filter = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    image = cv2.filter2D(image, -1, kernel=sharp_filter)\n",
    "\n",
    "    logger.debug(\"Reshaping and converting image to float32.\")\n",
    "    pixels = image.reshape(-1, 3)\n",
    "    pixels = np.float32(pixels)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    k = 5\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    centers = np.uint8(centers)\n",
    "    segmented_image = centers[labels.flatten()]\n",
    "    segmented_image = segmented_image.reshape(image.shape)\n",
    "\n",
    "    logger.debug(\"Calculating densities for each cluster.\")\n",
    "    densities = []\n",
    "    for i in range(k):\n",
    "        cluster_mask = (labels == i).reshape(image.shape[:2]).astype(np.uint8) * 255\n",
    "        density = cluster_density(cluster_mask)\n",
    "        densities.append(density)\n",
    "    selected_cluster = np.argmin(densities)\n",
    "    logger.debug(f\"Selected cluster: {selected_cluster}\")\n",
    "\n",
    "    mask = (labels == selected_cluster).reshape(image.shape[:2])\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask.astype(np.uint8) * 255)\n",
    "\n",
    "    logger.debug(\"Creating binary image.\")\n",
    "    binary_image = cv2.threshold(cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    binary_image = cv2.bitwise_not(binary_image)\n",
    "    binary_image = cv2.erode(binary_image, np.ones((2, 2), np.uint8))\n",
    "\n",
    "    logger.debug(\"Finding contours.\")\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "    combined_contours = combine_vertical_contours(contours)\n",
    "\n",
    "    captcha_h = max(map(lambda c: c[3] - c[1], combined_contours))\n",
    "    symbols = []\n",
    "\n",
    "    logger.debug(\"Processing each contour to extract symbols.\")\n",
    "    for x1, y1, x2, y2 in combined_contours:\n",
    "        symbol = binary_image[y1:y2, x1:x2]\n",
    "        symbol = cv2.dilate(symbol, np.ones((2, 2), np.uint8))\n",
    "        h = int(30 / captcha_h * (y2 - y1))\n",
    "        w = int(h * ((x2 - x1) / (y2 - y1)))\n",
    "        w = min(37, max(1, w))  # Ensure width is at least 1\n",
    "        h = max(1, h)  # Ensure height is at least 1\n",
    "\n",
    "        logger.debug(f\"Resizing symbol: target size ({w}, {h})\")\n",
    "        symbol = cv2.resize(symbol, (w, h), interpolation=cv2.INTER_AREA)\n",
    "        reshaped = np.zeros((60, 40), dtype=np.uint8)\n",
    "        reshaped[30 - h + 10:40, 3:3 + w] = symbol\n",
    "        reshaped = cv2.bitwise_not(reshaped)\n",
    "        symbols.append(reshaped)\n",
    "\n",
    "    logger.info(f\"Preprocessing complete. Number of symbols: {len(symbols)}\")\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a0bceb-75a1-4463-b0b4-1e9a0bb1c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    logger.info(f\"Loading data from directory: {data_dir}\")\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            symbols = preprocess_image(os.path.join(data_dir, filename))\n",
    "            # Добавьте метки для каждого символа\n",
    "            image_labels = list(filename.split('.')[0])\n",
    "            if len(symbols) != len(image_labels):\n",
    "                logger.warning(f\"Mismatch in symbols ({len(symbols)}) and labels ({len(image_labels)}) for {filename}\")\n",
    "                continue\n",
    "            else:\n",
    "                images.extend(symbols)\n",
    "                labels.extend(image_labels)\n",
    "    logger.info(f\"Loaded {len(images)} images and {len(labels)} labels.\")\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57bdb693-f8b8-4d01-8ad0-ae9cf9179993",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'cpt_gen/generated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpt_gen/generated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m      2\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m         symbols \u001b[38;5;241m=\u001b[39m preprocess_image(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, filename))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'cpt_gen/generated'"
     ]
    }
   ],
   "source": [
    "images, labels = load_data('cpt_gen/generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f641b-c8be-472a-9ea1-f42774907a61",
   "metadata": {},
   "source": [
    "## Проверка количества изображений и меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3b8dc-9313-4fb7-9d44-bd2f299c12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(images) == len(labels), f\"Mismatch: {len(images)} images and {len(labels)} labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc13f2d-49cb-44c0-859b-5bd4d015ff44",
   "metadata": {},
   "source": [
    "## Создание словаря для преобразования символов в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61159ee9-4197-4672-9377-acfe9130265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(set(labels))\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "logger.debug(f\"Unique labels: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f7a41-e91a-4e26-88f3-81f66f1e3872",
   "metadata": {},
   "source": [
    "## Преобразование меток в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857dfcd-d5bb-49c7-89c3-14378ab8d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_indices = np.array([label_to_index[label] for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eec193-bf11-489b-ae2e-b81ea8e02d5b",
   "metadata": {},
   "source": [
    "## Преобразование индексов в категориальные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad45db-10a4-4efc-a0e7-dc95cd926e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(unique_labels)\n",
    "labels_categorical = to_categorical(labels_indices, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4707d-010d-4b8f-bbbf-d5a187268d46",
   "metadata": {},
   "source": [
    "## Нормализация изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47e7e5-2b7f-4072-a118-578bfec25086",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f024c8-cfc1-4f16-a2d2-54629ed4cb7f",
   "metadata": {},
   "source": [
    "## Изменение формы изображений для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68059436-0c9e-451e-b3c0-ac40c7048219",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape((-1, 40, 60, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee16ba5-2e72-4b36-a7f0-5c68d87b5d46",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ab914-461c-4a58-b3a1-cffc3647c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ETB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Creating the model.\")\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(40, 60, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03f162-cd49-4b99-9210-b285610e0d4f",
   "metadata": {},
   "source": [
    "## Компиляция модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429ed24-1a64-482e-af85-4c627581bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Compiling the model.\")\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb950e-e5f0-4bc7-82be-991926f97e29",
   "metadata": {},
   "source": [
    "## Обучение и сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784fd72-d9bf-4a2d-9acd-9b194e6d712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.7006 - loss: 1.2961 - val_accuracy: 0.9676 - val_loss: 0.1107\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9737 - loss: 0.0840 - val_accuracy: 0.9751 - val_loss: 0.0656\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9786 - loss: 0.0571 - val_accuracy: 0.9808 - val_loss: 0.0677\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0470 - val_accuracy: 0.9781 - val_loss: 0.0542\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.0439 - val_accuracy: 0.9793 - val_loss: 0.0623\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0478 - val_accuracy: 0.9835 - val_loss: 0.0534\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0428 - val_accuracy: 0.9830 - val_loss: 0.0555\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.0364 - val_accuracy: 0.9845 - val_loss: 0.0475\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0402 - val_accuracy: 0.9865 - val_loss: 0.0514\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0326 - val_accuracy: 0.9814 - val_loss: 0.0520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2633093a210>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"Training the model.\")\n",
    "model.fit(images, labels_categorical, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7e294-922e-4069-a684-73742f59f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Saving the model.\")\n",
    "model.save('my_model_k.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d828fe0-7bfd-463d-acc2-5be2f309dfcb",
   "metadata": {},
   "source": [
    "## Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062bd87-2ee7-471c-973b-131838324e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m855/855\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0288\n",
      "Loss: 0.03831688314676285, Accuracy: 0.9836905002593994\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Evaluating the model.\")\n",
    "loss, accuracy = model.evaluate(images, labels_categorical)\n",
    "logger.info(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58dfdd-a254-44e0-9475-98f6de4a80d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
